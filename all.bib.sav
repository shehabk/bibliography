% Encoding: ISO-8859-1

@InProceedings{liu2014feature,
  author       = {Liu, Ping and Zhou, Joey Tianyi and Tsang, Ivor Wai-Hung and Meng, Zibo and Han, Shizhong and Tong, Yan},
  title        = {Feature disentangling machine-a novel approach of feature selection and disentangling in facial expression analysis},
  booktitle    = {European Conference on Computer Vision},
  year         = {2014},
  pages        = {151--166},
  organization = {Springer},
  file         = {:liu2014feature - Feature Disentangling Machine a Novel Approach of Feature Selection and Disentangling in Facial Expression Analysis.pdf:PDF},
  groups       = {MyGroup},
}

@Article{cai2017island,
  author  = {Cai, Jie and Meng, Zibo and Khan, Ahmed Shehab and Li, Ziyuan and Tong, Yan},
  title   = {{Island Loss for Learning Discriminative Features in Facial Expression Recognition}},
  journal = {arXiv preprint arXiv:1710.03144},
  year    = {2017},
  file    = {:cai2017island - Island Loss for Learning Discriminative Features in Facial Expression Recognition.pdf:PDF},
  groups  = {MyGroup},
  review  = {ITBN},
}

@InProceedings{meng2017identity,
  author       = {Meng, Zibo and Liu, Ping and Cai, Jie and Han, Shizhong and Tong, Yan},
  title        = {Identity-aware convolutional neural network for facial expression recognition},
  booktitle    = {Automatic Face \& Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on},
  year         = {2017},
  pages        = {558--565},
  organization = {IEEE},
  file         = {:meng2017identity - Identity Aware Convolutional Neural Network for Facial Expression Recognition.pdf:PDF},
  groups       = {MyGroup},
}

@InProceedings{han2016incremental,
  author    = {Han, Shizhong and Meng, Zibo and Khan, Ahmed-Shehab and Tong, Yan},
  title     = {Incremental boosting convolutional neural network for facial action unit recognition},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2016},
  pages     = {109--117},
  file      = {:han2016incremental - Incremental Boosting Convolutional Neural Network for Facial Action Unit Recognition.pdf:PDF},
  groups    = {MyGroup},
}

@InProceedings{chen2016infogan,
  author    = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  title     = {Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2016},
  pages     = {2172--2180},
  file      = {:chen2016infogan_ - Infogan_ Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets.pdf:PDF},
  groups    = {Conditional Adversarial},
}

@Article{tran2017representation,
  author   = {Tran, Luan and Yin, Xi and Liu, Xiaoming},
  title    = {Representation learning by rotating your faces},
  journal  = {arXiv preprint arXiv:1705.11136},
  year     = {2017},
  file     = {:tran2017representation - Representation Learning by Rotating Your Faces.pdf:PDF},
  groups   = {Image Translation GAN},
  keywords = {image translation,nips17},
}

@Article{li2018globala,
  author   = {Li, Peipei and Hu, Yibo and Li, Qi and He, Ran and Sun, Zhenan},
  title    = {Global and Local Consistent Age Generative Adversarial Networks},
  journal  = {arXiv preprint arXiv:1801.08390},
  year     = {2018},
  file     = {:li2018global - Global and Local Consistent Age Generative Adversarial Networks.pdf:PDF},
  groups   = {Face Synthesis GAN},
  keywords = {face synthesis},
}

@Article{zhu2017unpaired,
  author    = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  title     = {Unpaired image-to-image translation using cycle-consistent adversarial networks},
  journal   = {arXiv preprint arXiv:1703.10593},
  year      = {2017},
  file      = {:zhu2017unpaired - Unpaired Image to Image Translation Using Cycle Consistent Adversarial Networks.pdf:PDF},
  groups    = {Image Translation GAN},
  keywords  = {image translation,nips17,cyclegan},
  publisher = {ICCV},
}

@InProceedings{saad2017dyadgan,
  author    = {Saad Khan, Yuchi M and others},
  title     = {DyadGAN: Generating Facial Expressions in Dyadic Interactions},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  year      = {2017},
  pages     = {11--18},
  file      = {:saad2017dyadgan - DyadGAN_ Generating Facial Expressions in Dyadic Interactions.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
}

@InProceedings{kaneko2017generative,
  author    = {Kaneko, Takuhiro and Hiramatsu, Kaoru and Kashino, Kunio},
  title     = {Generative attribute controller with conditional filtered generative adversarial networks},
  booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2017},
  volume    = {2},
  file      = {:kaneko2017generative - Generative Attribute Controller with Conditional Filtered Generative Adversarial Networks.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
}

@Article{isola2017image,
  author   = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  title    = {Image-to-image translation with conditional adversarial networks},
  journal  = {arXiv preprint},
  year     = {2017},
  file     = {:isola2017image - Image to Image Translation with Conditional Adversarial Networks.pdf:PDF},
  groups   = {Image Translation GAN},
  keywords = {image translation,pix2pix,rank5},
  review   = {Pix2Pix},
}

@Article{dolhansky2017eye,
  author   = {Dolhansky, Brian and Ferrer, Cristian Canton},
  title    = {Eye In-Painting with Exemplar Generative Adversarial Networks},
  journal  = {arXiv preprint arXiv:1712.03999},
  year     = {2017},
  file     = {:dolhansky2017eye - Eye in Painting with Exemplar Generative Adversarial Networks.pdf:PDF},
  groups   = {Inpainting},
  keywords = {inpainting},
}

@Article{radford2015unsuperviseda,
  author   = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  title    = {Unsupervised representation learning with deep convolutional generative adversarial networks},
  journal  = {arXiv preprint arXiv:1511.06434},
  year     = {2015},
  file     = {:radford2015unsupervised - Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.pdf:PDF},
  groups   = {High Quality Image Generation},
  keywords = {DC-GAN,iclr, rank5},
}

@Article{mirza2014conditional,
  author   = {Mirza, Mehdi and Osindero, Simon},
  title    = {Conditional generative adversarial nets},
  journal  = {arXiv preprint arXiv:1411.1784},
  year     = {2014},
  file     = {:mirza2014conditional - Conditional Generative Adversarial Nets.pdf:PDF},
  groups   = {Theory GAN, Conditional Adversarial},
  keywords = {rank5},
}

@InProceedings{goodfellow2014generative,
  author    = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  title     = {Generative adversarial nets},
  booktitle = {Advances in neural information processing systems},
  year      = {2014},
  pages     = {2672--2680},
  file      = {:goodfellow2014generative - Generative adversarial nets.pdf:PDF},
  groups    = {Theory GAN},
  keywords  = {rank5},
}

@InProceedings{zhao2015joint,
  author       = {Zhao, Kaili and Chu, Wen-Sheng and De la Torre, Fernando and Cohn, Jeffrey F and Zhang, Honggang},
  title        = {Joint patch and multi-label learning for facial action unit detection},
  booktitle    = {Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on},
  year         = {2015},
  pages        = {2207--2216},
  organization = {IEEE},
  file         = {:zhao2015joint - Joint patch and multi-label learning for facial action unit detection.pdf:PDF},
  groups       = {AU},
  keywords     = {JPML},
}

@InProceedings{li2017action,
  author       = {Li, Wei and Abtahi, Farnaz and Zhu, Zhigang},
  title        = {Action unit detection with region adaptation, multi-labeling learning and optimal temporal fusing},
  booktitle    = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year         = {2017},
  pages        = {6766--6775},
  organization = {IEEE},
  file         = {:li2017action - Action unit detection with region adaptation, multi-labeling learning and optimal temporal fusing.pdf:PDF},
  groups       = {AU},
  owner        = {shehabk},
  timestamp    = {2018.02.10},
}

@InProceedings{zhao2016deep,
  author    = {Zhao, Kaili and Chu, Wen-Sheng and Zhang, Honggang},
  title     = {Deep region and multi-label learning for facial action unit detection},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {3391--3399},
  file      = {:zhao2016deep - Deep region and multi-label learning for facial action unit detection.pdf:PDF},
  groups    = {AU},
  keywords  = {DRML},
  owner     = {shehabk},
  timestamp = {2018.02.10},
}

@InProceedings{li2017eac,
  author       = {Li, Wei and Abtahi, Farnaz and Zhu, Zhigang and Yin, Lijun},
  title        = {Eac-net: A region-based deep enhancing and cropping approach for facial action unit detection},
  booktitle    = {Automatic Face \& Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on},
  year         = {2017},
  pages        = {103--110},
  organization = {IEEE},
  file         = {:li2017eac - Eac-net_ A region-based deep enhancing and cropping approach for facial action unit detection.pdf:PDF},
  groups       = {AU},
  owner        = {shehabk},
  review       = {This paper got recently got accepted in PAMI},
  timestamp    = {2018.02.10},
}

@Article{zhong2015learning,
  author    = {Zhong, Lin and Liu, Qingshan and Yang, Peng and Huang, Junzhou and Metaxas, Dimitris N},
  title     = {Learning multiscale active facial patches for expression analysis},
  journal   = {IEEE transactions on cybernetics},
  year      = {2015},
  volume    = {45},
  number    = {8},
  pages     = {1499--1510},
  file      = {:zhong2015learning - Learning multiscale active facial patches for expression analysis.pdf:PDF},
  groups    = {AU},
  owner     = {shehabk},
  publisher = {IEEE},
  timestamp = {2018.02.10},
}

@InProceedings{chang2009learning,
  author       = {Chang, Kai-Yueh and Liu, Tyng-Luh and Lai, Shang-Hong},
  title        = {Learning partially-observed hidden conditional random fields for facial expression recognition},
  booktitle    = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on},
  year         = {2009},
  pages        = {533--540},
  organization = {IEEE},
  file         = {:chang2009learning - Learning partially-observed hidden conditional random fields for facial expression recognition.pdf:PDF},
  groups       = {AU},
  owner        = {shehabk},
  timestamp    = {2018.02.10},
}

@InProceedings{chu2017learning,
  author       = {Chu, Wen-Sheng and De la Torre, Fernando and Cohn, Jeffrey F},
  title        = {Learning spatial and temporal cues for multi-label facial action unit detection},
  booktitle    = {Automatic Face \& Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on},
  year         = {2017},
  pages        = {25--32},
  organization = {IEEE},
  file         = {:chu2017learning - Learning spatial and temporal cues for multi-label facial action unit detection.pdf:PDF},
  groups       = {AU},
  owner        = {shehabk},
  timestamp    = {2018.02.10},
}

@InProceedings{eleftheriadis2015multi,
  author    = {Eleftheriadis, Stefanos and Rudovic, Ognjen and Pantic, Maja},
  title     = {Multi-conditional latent variable model for joint facial action unit detection},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
  year      = {2015},
  pages     = {3792--3800},
  file      = {:eleftheriadis2015multi - Multi-conditional latent variable model for joint facial action unit detection.pdf:PDF},
  groups    = {AU},
  owner     = {shehabk},
  timestamp = {2018.02.10},
}

@InProceedings{yang2014personalized,
  author       = {Yang, Shuang and Rudovic, Ognjen and Pavlovic, Vladimir and Pantic, Maja},
  title        = {Personalized modeling of facial action unit intensity},
  booktitle    = {International Symposium on Visual Computing},
  year         = {2014},
  pages        = {269--281},
  organization = {Springer},
  groups       = {AU},
  owner        = {shehabk},
  timestamp    = {2018.02.10},
}

@InProceedings{chu2013selective,
  author       = {Chu, Wen-Sheng and De la Torre, Fernando and Cohn, Jeffery F},
  title        = {Selective transfer machine for personalized facial action unit detection},
  booktitle    = {Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
  year         = {2013},
  pages        = {3515--3522},
  organization = {IEEE},
  file         = {:chu2013selective - Selective transfer machine for personalized facial action unit detection.pdf:PDF},
  groups       = {AU},
  owner        = {shehabk},
  timestamp    = {2018.02.10},
}

@Article{pavlovicdeep,
  author    = {Pavlovic, Vladimir and Schuller, Bj{\"o}ern and Pantic, Maja},
  title     = {Deep Structured Learning for Facial Action Unit Intensity Estimation},
  file      = {:pavlovicdeep - Deep Structured Learning for Facial Action Unit Intensity Estimation.pdf:PDF},
  groups    = {AU},
  owner     = {shehabk},
  timestamp = {2018.02.10},
}

@InProceedings{sangineto2014we,
  author       = {Sangineto, Enver and Zen, Gloria and Ricci, Elisa and Sebe, Nicu},
  title        = {We are not all equal: Personalizing models for facial expression analysis with transductive parameter transfer},
  booktitle    = {Proceedings of the 22nd ACM international conference on Multimedia},
  year         = {2014},
  pages        = {357--366},
  organization = {ACM},
  file         = {:sangineto2014we - We are not all equal_ Personalizing models for facial expression analysis with transductive parameter transfer.pdf:PDF},
  groups       = {AU},
  owner        = {shehabk},
  timestamp    = {2018.02.10},
}

@InProceedings{ding2017facenet2expnet,
  author       = {Ding, Hui and Zhou, Shaohua Kevin and Chellappa, Rama},
  title        = {Facenet2expnet: Regularizing a deep face recognition net for expression recognition},
  booktitle    = {Automatic Face \& Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on},
  year         = {2017},
  pages        = {118--126},
  organization = {IEEE},
  file         = {:ding2017facenet2expnet - Facenet2expnet_ Regularizing a deep face recognition net for expression recognition.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {person-independent},
  timestamp    = {2018.02.10},
}

@InProceedings{zhao2016peak,
  author       = {Zhao, Xiangyun and Liang, Xiaodan and Liu, Luoqi and Li, Teng and Han, Yugang and Vasconcelos, Nuno and Yan, Shuicheng},
  title        = {Peak-piloted deep network for facial expression recognition},
  booktitle    = {European conference on computer vision},
  year         = {2016},
  pages        = {425--442},
  organization = {Springer},
  file         = {:zhao2016peak - Peak-piloted deep network for facial expression recognition.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {person-independent, PPDN},
  timestamp    = {2018.02.10},
}

@Article{zhao2007dynamic,
  author    = {Zhao, Guoying and Pietikainen, Matti},
  title     = {Dynamic texture recognition using local binary patterns with an application to facial expressions},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  year      = {2007},
  volume    = {29},
  number    = {6},
  pages     = {915--928},
  file      = {:zhao2007dynamic - Dynamic texture recognition using local binary patterns with an application to facial expressions.pdf:PDF},
  groups    = {Expression},
  owner     = {shehabk},
  publisher = {IEEE},
  review    = {LBP-TOP},
  timestamp = {2018.02.10},
}

@InProceedings{klaser2008spatio,
  author       = {Klaser, Alexander and Marsza{\l}ek, Marcin and Schmid, Cordelia},
  title        = {A spatio-temporal descriptor based on 3d-gradients},
  booktitle    = {BMVC 2008-19th British Machine Vision Conference},
  year         = {2008},
  pages        = {275--1},
  organization = {British Machine Vision Association},
  file         = {:klaser2008spatio - A spatio-temporal descriptor based on 3d-gradients.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {HOG-3D},
  timestamp    = {2018.02.10},
}

@InProceedings{liu2014deeply,
  author       = {Liu, Mengyi and Li, Shaoxin and Shan, Shiguang and Wang, Ruiping and Chen, Xilin},
  title        = {Deeply learning deformable facial action parts model for dynamic expression analysis},
  booktitle    = {Asian conference on computer vision},
  year         = {2014},
  pages        = {143--157},
  organization = {Springer},
  file         = {:liu2014deeply - Deeply learning deformable facial action parts model for dynamic expression analysis.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {3DCNN-DAP},
  timestamp    = {2018.02.10},
}

@InProceedings{liu2014learning,
  author       = {Liu, Mengyi and Shan, Shiguang and Wang, Ruiping and Chen, Xilin},
  title        = {Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition},
  booktitle    = {Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on},
  year         = {2014},
  pages        = {1749--1756},
  organization = {IEEE},
  file         = {:liu2014learning - Learning expressionlets on spatio-temporal manifold for dynamic facial expression recognition.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {STM-Explet},
  timestamp    = {2018.02.10},
}

@InProceedings{jung2015joint,
  author       = {Jung, Heechul and Lee, Sihaeng and Yim, Junho and Park, Sunjeong and Kim, Junmo},
  title        = {Joint fine-tuning in deep neural networks for facial expression recognition},
  booktitle    = {Computer Vision (ICCV), 2015 IEEE International Conference on},
  year         = {2015},
  pages        = {2983--2991},
  organization = {IEEE},
  file         = {:jung2015joint - Joint fine-tuning in deep neural networks for facial expression recognition.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {DTAGN},
  timestamp    = {2018.02.10},
}

@InProceedings{wang2013capturing,
  author       = {Wang, Ziheng and Wang, Shangfei and Ji, Qiang},
  title        = {Capturing complex spatio-temporal relations among facial muscles for facial expression recognition},
  booktitle    = {Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on},
  year         = {2013},
  pages        = {3422--3429},
  organization = {IEEE},
  file         = {:wang2013capturing - Capturing complex spatio-temporal relations among facial muscles for facial expression recognition.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  timestamp    = {2018.02.10},
}

@Article{sariyanidi2017learning,
  author    = {Sariyanidi, Evangelos and Gunes, Hatice and Cavallaro, Andrea},
  title     = {Learning bases of activity for facial expression recognition},
  journal   = {IEEE Transactions on Image Processing},
  year      = {2017},
  volume    = {26},
  number    = {4},
  pages     = {1965--1978},
  file      = {:sariyanidi2017learning - Learning bases of activity for facial expression recognition.pdf:PDF},
  groups    = {Expression},
  owner     = {shehabk},
  publisher = {IEEE},
  review    = {F-Bases},
  timestamp = {2018.02.10},
}

@InProceedings{ptucha2011manifold,
  author       = {Ptucha, Raymond and Tsagkatakis, Grigorios and Savakis, Andreas},
  title        = {Manifold based sparse representation for robust expression recognition without neutral subtraction},
  booktitle    = {Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on},
  year         = {2011},
  pages        = {2136--2143},
  organization = {IEEE},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {MSR},
  timestamp    = {2018.02.10},
}

@InProceedings{jain2011facial,
  author       = {Jain, Suyog and Hu, Changbo and Aggarwal, Jake K},
  title        = {Facial expression recognition with temporal modeling of shapes},
  booktitle    = {Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on},
  year         = {2011},
  pages        = {1642--1649},
  organization = {IEEE},
  file         = {:jain2011facial - Facial expression recognition with temporal modeling of shapes.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {TMS},
  timestamp    = {2018.02.10},
}

@InProceedings{sanin2013spatio,
  author       = {Sanin, Andres and Sanderson, Conrad and Harandi, Mehrtash T and Lovell, Brian C},
  title        = {Spatio-temporal covariance descriptors for action and gesture recognition},
  booktitle    = {Applications of Computer Vision (WACV), 2013 IEEE Workshop on},
  year         = {2013},
  pages        = {103--110},
  organization = {IEEE},
  file         = {:sanin2013spatio - Spatio-temporal covariance descriptors for action and gesture recognition.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {Cov3D},
  timestamp    = {2018.02.10},
}

@InProceedings{mollahosseini2016going,
  author       = {Mollahosseini, Ali and Chan, David and Mahoor, Mohammad H},
  title        = {Going deeper in facial expression recognition using deep neural networks},
  booktitle    = {Applications of Computer Vision (WACV), 2016 IEEE Winter Conference on},
  year         = {2016},
  pages        = {1--10},
  organization = {IEEE},
  file         = {:mollahosseini2016going - Going deeper in facial expression recognition using deep neural networks.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {Inception},
  timestamp    = {2018.02.10},
}

@InProceedings{sikka2016lomo,
  author    = {Sikka, Karan and Sharma, Gaurav and Bartlett, Marian},
  title     = {Lomo: Latent ordinal model for facial analysis in videos},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {5580--5589},
  file      = {:sikka2016lomo - Lomo_ Latent ordinal model for facial analysis in videos.pdf:PDF},
  groups    = {Expression},
  owner     = {shehabk},
  review    = {LOMO},
  timestamp = {2018.02.10},
}

@InProceedings{li2017reliable,
  author       = {Li, Shan and Deng, Weihong and Du, JunPing},
  title        = {Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild},
  booktitle    = {Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on},
  year         = {2017},
  pages        = {2584--2593},
  organization = {IEEE},
  file         = {:li2017reliable - Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild.pdf:PDF},
  groups       = {Expression},
  owner        = {shehabk},
  review       = {DLP-CNN},
  timestamp    = {2018.02.10},
}

@Article{chu2017selective,
  author    = {Chu, Wen-Sheng and De la Torre, Fernando and Cohn, Jeffrey F},
  title     = {Selective transfer machine for personalized facial expression analysis},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  year      = {2017},
  volume    = {39},
  number    = {3},
  pages     = {529--545},
  groups    = {Expression},
  owner     = {shehabk},
  publisher = {IEEE},
  review    = {STM},
  timestamp = {2018.02.10},
}

@Article{ding2017exprgan,
  author   = {Ding, Hui and Sricharan, Kumar and Chellappa, Rama},
  title    = {Exprgan: Facial expression editing with controllable expression intensity},
  journal  = {arXiv preprint arXiv:1709.03842},
  year     = {2017},
  file     = {:ding2017exprgan - Exprgan_ Facial expression editing with controllable expression intensity.pdf:PDF},
  groups   = {Expression, Face Synthesis GAN},
  keywords = {face synthesis},
}

@Article{yeh2016semantic,
  author  = {Yeh, Raymond and Liu, Ziwei and Goldman, Dan B and Agarwala, Aseem},
  title   = {Semantic facial expression editing using autoencoded flow},
  journal = {arXiv preprint arXiv:1611.09961},
  year    = {2016},
  groups  = {Expression},
}

@Misc{ekamn1978facial,
  author    = {Ekamn, P and Friesen, W},
  title     = {Facial action coding system (FACS): manual},
  year      = {1978},
  file      = {:ekamn1978facial - Facial action coding system (FACS)_ manual.pdf:PDF},
  groups    = {MyGroup, AU},
  keywords  = {Manual},
  owner     = {shehabk},
  publisher = {Consulting Psychologists Press Palo Alto},
  timestamp = {2018.02.12},
}

@Article{tong2010unified,
  author    = {Tong, Yan and Chen, Jixu and Ji, Qiang},
  title     = {A unified probabilistic framework for spontaneous facial action modeling and understanding},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  year      = {2010},
  volume    = {32},
  number    = {2},
  pages     = {258--273},
  file      = {:tong2010unified - A unified probabilistic framework for spontaneous facial action modeling and understanding.pdf:PDF},
  groups    = {MyGroup},
  owner     = {shehabk},
  publisher = {IEEE},
  timestamp = {2018.02.12},
}

@Article{tong2007facial,
  author    = {Tong, Yan and Liao, Wenhui and Ji, Qiang},
  title     = {Facial action unit recognition by exploiting their dynamic and semantic relationships},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  year      = {2007},
  volume    = {29},
  number    = {10},
  file      = {:tong2007facial - Facial action unit recognition by exploiting their dynamic and semantic relationships.pdf:PDF},
  groups    = {MyGroup},
  owner     = {shehabk},
  publisher = {IEEE},
  timestamp = {2018.02.12},
}

@Article{sariyanidi2015automatic,
  author    = {Sariyanidi, Evangelos and Gunes, Hatice and Cavallaro, Andrea},
  title     = {Automatic analysis of facial affect: A survey of registration, representation, and recognition},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  year      = {2015},
  volume    = {37},
  number    = {6},
  pages     = {1113--1133},
  file      = {:sariyanidi2015automatic - Automatic analysis of facial affect_ A survey of registration, representation, and recognition.pdf:PDF},
  groups    = {Expression},
  owner     = {shehabk},
  publisher = {IEEE},
  timestamp = {2018.02.12},
}

@Article{song2017geometry,
  author    = {Song, Lingxiao and Lu, Zhihe and He, Ran and Sun, Zhenan and Tan, Tieniu},
  title     = {Geometry Guided Adversarial Facial Expression Synthesis},
  journal   = {arXiv preprint arXiv:1712.03474},
  year      = {2017},
  file      = {:song2017geometry - Geometry Guided Adversarial Facial Expression Synthesis.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Article{antipov2017face,
  author    = {Antipov, Grigory and Baccouche, Moez and Dugelay, Jean-Luc},
  title     = {Face aging with conditional generative adversarial networks},
  journal   = {arXiv preprint arXiv:1702.01983},
  year      = {2017},
  file      = {:antipov2017face - Face aging with conditional generative adversarial networks.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Article{di2017gp,
  author    = {Di, Xing and Sindagi, Vishwanath A and Patel, Vishal M},
  title     = {GP-GAN: Gender Preserving GAN for Synthesizing Faces from Landmarks},
  journal   = {arXiv preprint arXiv:1710.00962},
  year      = {2017},
  file      = {:di2017gp - GP-GAN_ Gender Preserving GAN for Synthesizing Faces from Landmarks.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Article{chang2017chinese,
  author    = {Chang, Jie and Gu, Yujun and Zhang, Ya},
  title     = {Chinese Typeface Transformation with Hierarchical Adversarial Network},
  journal   = {arXiv preprint arXiv:1711.06448},
  year      = {2017},
  file      = {:chang2017chinese - Chinese Typeface Transformation with Hierarchical Adversarial Network.pdf:PDF},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Article{huang2017face,
  author    = {Huang, Zhiwu and Kratzwald, Bernhard and Paudel, Danda Pani and Wu, Jiqing and Van Gool, Luc},
  title     = {Face Translation between Images and Videos using Identity-aware CycleGAN},
  journal   = {arXiv preprint arXiv:1712.00971},
  year      = {2017},
  file      = {:huang2017face - Face Translation between Images and Videos using Identity-aware CycleGAN.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Article{zhou2017label,
  author    = {Zhou, Hao and Sun, Jin and Yacoob, Yaser and Jacobs, David W},
  title     = {Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Face Images},
  journal   = {arXiv preprint arXiv:1709.01993},
  year      = {2017},
  file      = {:zhou2017label - Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Face Images.pdf:PDF},
  groups    = {Face Synthesis GAN},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Article{huang2017facea,
  author    = {Huang, Rui and Zhang, Shu and Li, Tianyu and He, Ran and others},
  title     = {Beyond face rotation: Global and local perception gan for photorealistic and identity preserving frontal view synthesis},
  journal   = {arXiv preprint arXiv:1704.04086},
  year      = {2017},
  file      = {:huang2017facea - Beyond face rotation_ Global and local perception gan for photorealistic and identity preserving frontal view synthesis.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis,iccv17},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Book{bishop2006pattern,
  title           = {Pattern Recognition and Machine Learning},
  publisher       = {Springer},
  year            = {2006},
  author          = {Bishop, Christopher M.},
  isbn            = {978-0387-31073-2},
  bib2html_rescat = {General ML},
  file            = {:bishop2006pattern - Pattern Recognition and Machine Learning.pdf:PDF},
  groups          = {Books},
  keywords        = {pr,bishop},
  url             = {http://research.microsoft.com/en-us/um/people/cmbishop/prml/},
}

@Book{Duda01a,
  title     = {Pattern Classification (2nd Ed)},
  publisher = {Wiley},
  year      = {2001},
  author    = {Richard O. Duda and Peter E. Hart and David G. Stork},
  annote    = {SIGNATUR = 785.172},
  file      = {:Duda01a - Pattern Classification (2nd Ed).pdf:PDF},
  groups    = {Books},
  keywords  = {pr,duda},
  place     = {Favoritenstrasse 9/4th Floor/1863},
}

@Book{Goodfellow-et-al-2016,
  title     = {Deep Learning},
  publisher = {MIT Press},
  year      = {2016},
  author    = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
  note      = {\url{http://www.deeplearningbook.org}},
  file      = {:Goodfellow-et-al-2016 - Deep Learning.pdf:PDF},
  groups    = {Books},
  keywords  = {pr,goodfellow},
}

@Book{murphy2012machine,
  title    = {Machine learning: a probabilistic perspective},
  year     = {2012},
  author   = {Kevin P Murphy},
  address  = {Cambridge, MA},
  file     = {:murphy2012machine - Machine learning_ a probabilistic perspective.pdf:PDF},
  groups   = {Books},
  keywords = {pr,murphy},
}

@InProceedings{patternsolution,
  title    = {Solution Duda Book},
  file     = {:PCDudaHartStorkSlotions.pdf:PDF},
  groups   = {Books},
  keywords = {pr_sol,duda},
}

@Manual{solution,
  title     = {Solution Bishop Book},
  file      = {:PRML_solution_full.pdf:PDF},
  groups    = {Books},
  keywords  = {pr_sol,bishop},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Book{computer,
  title     = {Computer vision_ A modern approach-Prentice Hall (2011)},
  file      = {:David A. Forsyth, Jean Ponce-Computer vision_ A modern approach-Prentice Hall (2011).pdf:PDF},
  groups    = {Books},
  keywords  = {cv},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Book{probabilistic,
  title     = {Probabilistic graphical models _ principles and techniques-MIT Press (2009.pdf:PDF},
  file      = {:(Adaptive computation and machine learning) Daphne Koller_ Nir Friedman -Probabilistic graphical models _ principles and techniques-MIT Press (2009.pdf:PDF},
  groups    = {Books},
  keywords  = {pgm},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Article{goodfellow2016nips,
  author    = {Goodfellow, Ian},
  title     = {NIPS 2016 tutorial: Generative adversarial networks},
  journal   = {arXiv preprint arXiv:1701.00160},
  year      = {2016},
  file      = {:goodfellow2016nips - NIPS 2016 tutorial_ Generative adversarial networks.pdf:PDF;:goodfellow2016nips - NIPS 2016 tutorial_ Generative adversarial networks_slides.pdf:PDF},
  groups    = {Tutorials GAN},
  keywords  = {tutorial},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@Article{goodfellow2014distinguishability,
  author    = {Goodfellow, Ian J},
  title     = {On distinguishability criteria for estimating generative models},
  journal   = {arXiv preprint arXiv:1412.6515},
  year      = {2014},
  file      = {:goodfellow2014distinguishability - On distinguishability criteria for estimating generative models.pdf:PDF},
  groups    = {Theory GAN},
  owner     = {shehabk},
  timestamp = {2018.02.19},
}

@InProceedings{zhao2017dual,
  author    = {Zhao, Jian and Xiong, Lin and Jayashree, Panasonic Karlekar and Li, Jianshu and Zhao, Fang and Wang, Zhecan and Pranata, Panasonic Sugiri and Shen, Panasonic Shengmei and Yan, Shuicheng and Feng, Jiashi},
  title     = {Dual-agent gans for photorealistic and identity preserving profile face synthesis},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  pages     = {65--75},
  file      = {:zhao2017dual - Dual-agent gans for photorealistic and identity preserving profile face synthesis.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis,nips17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@InProceedings{gansy,
  author   = {Y LeCun},
  title    = {Energy-Based GANs \& other Adversarial things},
  file     = {:gansy - Y LeCun.pdf:PDF},
  groups   = {Tutorials GAN},
  keywords = {tutorial},
}

@Standard{soumithhow,
  title     = {How to Train a GAN},
  author    = {Soumith},
  url       = {https://github.com/soumith/ganhacks},
  groups    = {Tutorials GAN},
  keywords  = {tutorial},
  owner     = {shehabk},
  review    = {12) If you have labels, use them (Say For example, Expression Classification.)},
  timestamp = {2018.02.20},
}

@InProceedings{salimans2016improved,
  author    = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
  title     = {Improved techniques for training gans},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2016},
  pages     = {2234--2242},
  file      = {:salimans2016improved - Improved techniques for training gans.pdf:PDF},
  groups    = {Tutorials GAN},
  url       = {https://github.com/openai/improved-gan},
}

@InProceedings{boosting2017for,
  title    = {Deep Boosting and of Complementary and Networks for Large-Scale},
  year     = {2017},
  file     = {:boosting2017for - _____For Peer Review Only.pdf:PDF},
  groups   = {paper review},
  keywords = {deep boosting, large-scale visual recognition, learning complexities},
}

@InProceedings{expression2018for,
  title    = {Facial Expression and Recognition with Active and Local Shape},
  year     = {2018},
  file     = {:expression2018for - _____For Peer Review Only.pdf:PDF},
  groups   = {paper review},
  keywords = {Feature representation < I.4.7 Feature Measurement < I.4 Image Processing and Computer Vision < I Computing Methodologie},
}

@InProceedings{shen2017learning,
  author       = {Shen, Wei and Liu, Rujie},
  title        = {Learning residual images for face attribute manipulation},
  booktitle    = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year         = {2017},
  pages        = {1225--1233},
  organization = {IEEE},
  file         = {:shen2017learning - Learning residual images for face attribute manipulation.pdf:PDF},
  groups       = {Face Synthesis GAN},
  keywords     = {face synthesis,cvpr17},
  owner        = {shehabk},
  timestamp    = {2018-02-20},
  url          = {https://github.com/Zhongdao/FaceAttributeManipulation},
}

@Article{brock2016neural,
  author    = {Brock, Andrew and Lim, Theodore and Ritchie, James M and Weston, Nick},
  title     = {Neural photo editing with introspective adversarial networks},
  journal   = {arXiv preprint arXiv:1609.07093},
  year      = {2016},
  file      = {:brock2016neural - Neural photo editing with introspective adversarial networks.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis,iclr17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@Article{shu2017neural,
  author    = {Shu, Zhixin and Yumer, Ersin and Hadap, Sunil and Sunkavalli, Kalyan and Shechtman, Eli and Samaras, Dimitris},
  title     = {Neural face editing with intrinsic image disentangling},
  journal   = {arXiv preprint arXiv:1704.04131},
  year      = {2017},
  file      = {:shu2017neural - Neural face editing with intrinsic image disentangling.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis,cvpr17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@Article{zhou2017genegan,
  author    = {Zhou, Shuchang and Xiao, Taihong and Yang, Yi and Feng, Dieqiao and He, Qinyao and He, Weiran},
  title     = {Genegan: Learning object transfiguration and attribute subspace from unpaired data},
  journal   = {arXiv preprint arXiv:1705.04932},
  year      = {2017},
  file      = {:zhou2017genegan - Genegan_ Learning object transfiguration and attribute subspace from unpaired data.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis,bmvc17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
  url       = {https://github.com/Prinsphield/GeneGAN},
}

@Article{choi2017stargan,
  author    = {Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
  title     = {StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation},
  journal   = {arXiv preprint arXiv:1711.09020},
  year      = {2017},
  file      = {:choi2017stargan - StarGAN_ Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
  owner     = {shehabk},
  timestamp = {2018-02-20},
  url       = {https://github.com/yunjey/StarGAN},
}

@Article{perarnau2016invertible,
  author    = {Perarnau, Guim and van de Weijer, Joost and Raducanu, Bogdan and {\'A}lvarez, Jose M},
  title     = {Invertible Conditional GANs for image editing.(2016)},
  journal   = {arXiv preprint arXiv:1611.06355},
  year      = {2016},
  file      = {:perarnau2016invertible - Invertible Conditional GANs for image editing.(2016).pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
  owner     = {shehabk},
  timestamp = {2018-02-20},
  url       = {https://github.com/Guim3/IcGAN},
}

@InProceedings{liu2016coupled,
  author    = {Liu, Ming-Yu and Tuzel, Oncel},
  title     = {Coupled generative adversarial networks},
  booktitle = {Advances in neural information processing systems},
  year      = {2016},
  pages     = {469--477},
  file      = {:liu2016coupled - Coupled generative adversarial networks.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis,image translation,nips17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
  url       = {https://github.com/andrewliao11/CoGAN-tensorflow},
}

@Article{boesenlindbolarsen2015autoencoding,
  author    = {Boesen Lindbo Larsen, Anders and Kaae S{\o}nderby, S{\o}ren and Larochelle, Hugo and Winther, Ole},
  title     = {Autoencoding beyond pixels using a learned similarity metric},
  journal   = {arXiv preprint arXiv:1512.09300},
  year      = {2015},
  file      = {:boesenlindbolarsen2015autoencoding - Autoencoding beyond pixels using a learned similarity metric.pdf:PDF},
  groups    = {Face Synthesis GAN},
  keywords  = {face synthesis},
  owner     = {shehabk},
  timestamp = {2018-02-20},
  url       = {https://github.com/zhangqianhui/vae-gan-tensorflow},
}

@Article{kim2017learning,
  author    = {Kim, Taeksoo and Cha, Moonsu and Kim, Hyunsoo and Lee, Jungkwon and Kim, Jiwon},
  title     = {Learning to discover cross-domain relations with generative adversarial networks},
  journal   = {arXiv preprint arXiv:1703.05192},
  year      = {2017},
  file      = {:kim2017learning - Learning to discover cross-domain relations with generative adversarial networks.pdf:PDF},
  groups    = {Image Translation GAN},
  keywords  = {image translation,DISCO-GAN},
  owner     = {shehabk},
  timestamp = {2018-02-20},
  url       = {https://github.com/carpedm20/DiscoGAN-pytorch},
}

@InProceedings{liu2017unsupervised,
  author    = {Liu, Ming-Yu and Breuel, Thomas and Kautz, Jan},
  title     = {Unsupervised image-to-image translation networks},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  pages     = {700--708},
  file      = {:liu2017unsupervised - Unsupervised image-to-image translation networks.pdf:PDF},
  groups    = {Image Translation GAN},
  keywords  = {image translation,nips17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
  url       = {https://github.com/mingyuliutw/UNIT},
}

@InProceedings{gan2017triangle,
  author    = {Gan, Zhe and Chen, Liqun and Wang, Weiyao and Pu, Yuchen and Zhang, Yizhe and Liu, Hao and Li, Chunyuan and Carin, Lawrence},
  title     = {Triangle generative adversarial networks},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  pages     = {5253--5262},
  file      = {:gan2017triangle - Triangle generative adversarial networks.pdf:PDF},
  groups    = {Image Translation GAN},
  keywords  = {image translation,nips17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@InProceedings{zhang2017st,
  author    = {Zhang, Jichao and Zhong, Fan and Cao, Gongze and Qin, Xueying},
  title     = {ST-GAN: Unsupervised Facial Image Semantic Transformation Using Generative Adversarial Networks},
  booktitle = {Asian Conference on Machine Learning},
  year      = {2017},
  pages     = {248--263},
  file      = {:zhang2017st - ST-GAN_ Unsupervised Facial Image Semantic Transformation Using Generative Adversarial Networks.pdf:PDF},
  groups    = {Image Translation GAN},
  keywords  = {image translation,acml17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@Article{wang2017high,
  author    = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  title     = {High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs},
  journal   = {arXiv preprint arXiv:1711.11585},
  year      = {2017},
  file      = {:wang2017high - High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs.pdf:PDF},
  groups    = {Image Translation GAN},
  keywords  = {image translation,pix2pixHD,nvidia},
  owner     = {shehabk},
  timestamp = {2018-02-20},
  url       = {https://github.com/NVIDIA/pix2pixHD},
}

@Article{royer2017xgan,
  author    = {Royer, Am{\'e}lie and Bousmalis, Konstantinos and Gouws, Stephan and Bertsch, Fred and Moressi, Inbar and Cole, Forrester and Murphy, Kevin},
  title     = {XGAN: Unsupervised Image-to-Image Translation for many-to-many Mappings},
  journal   = {arXiv preprint arXiv:1711.05139},
  year      = {2017},
  file      = {:royer2017xgan - XGAN_ Unsupervised Image-to-Image Translation for many-to-many Mappings.pdf:PDF},
  groups    = {Image Translation GAN},
  keywords  = {image translation},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@InProceedings{zhu2017multimodal,
  author        = {Zhu, Jun-Yan and Zhang, Richard and Pathak, Deepak and Darrell, Trevor and Efros, Alexei A and Wang, Oliver and Shechtman, Eli},
  title         = {Toward multimodal image-to-image translation},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2017},
  pages         = {465--476},
  __markedentry = {[shehabk:]},
  file          = {:zhu2017multimodal - Toward multimodal image-to-image translation.pdf:PDF},
  groups        = {Image Translation GAN},
  keywords      = {image translation,nips17,berkeley},
  owner         = {shehabk},
  timestamp     = {2018-02-20},
}

@InProceedings{zhang2017stackgan,
  author    = {Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Huang, Xiaolei and Wang, Xiaogang and Metaxas, Dimitris},
  title     = {Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks},
  booktitle = {IEEE Int. Conf. Comput. Vision (ICCV)},
  year      = {2017},
  pages     = {5907--5915},
  file      = {:zhang2017stackgan - Stackgan_ Text to photo-realistic image synthesis with stacked generative adversarial networks.pdf:PDF},
  groups    = {High Quality Image Generation},
  keywords  = {high quality,iccv17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@InProceedings{tolstikhin2017adagan,
  author    = {Tolstikhin, Ilya O and Gelly, Sylvain and Bousquet, Olivier and Simon-Gabriel, Carl-Johann and Sch{\"o}lkopf, Bernhard},
  title     = {Adagan: Boosting generative models},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  pages     = {5430--5439},
  groups    = {Unlclassified},
  keywords  = {ensemble,nips17,google brain},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@Article{yeh2016semantica,
  author    = {Yeh, Raymond and Chen, Chen and Lim, Teck Yian and Hasegawa-Johnson, Mark and Do, Minh N},
  title     = {Semantic image inpainting with perceptual and contextual losses},
  journal   = {arXiv preprint arXiv:1607.07539},
  year      = {2016},
  file      = {:yeh2016semantic - Semantic image inpainting with perceptual and contextual losses.pdf:PDF},
  groups    = {Inpainting},
  keywords  = {inpainting,cvpr17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@InProceedings{pathak2016context,
  author    = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  title     = {Context encoders: Feature learning by inpainting},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2016},
  pages     = {2536--2544},
  file      = {:pathak2016context - Context encoders_ Feature learning by inpainting.pdf:PDF},
  groups    = {Inpainting},
  keywords  = {inpainting,iccv17},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@Article{denton2016semi,
  author    = {Denton, Emily and Gross, Sam and Fergus, Rob},
  title     = {Semi-supervised learning with context-conditional generative adversarial networks},
  journal   = {arXiv preprint arXiv:1611.06430},
  year      = {2016},
  file      = {:denton2016semi - Semi-supervised learning with context-conditional generative adversarial networks.pdf:PDF},
  groups    = {Inpainting},
  keywords  = {inpainting},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@InProceedings{li2017generative,
  author    = {Li, Yijun and Liu, Sifei and Yang, Jimei and Yang, Ming-Hsuan},
  title     = {Generative face completion},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year      = {2017},
  volume    = {1},
  number    = {3},
  pages     = {6},
  file      = {:li2017generative - Generative face completion.pdf:PDF},
  groups    = {Inpainting},
  keywords  = {inpainting},
  owner     = {shehabk},
  timestamp = {2018-02-20},
}

@Article{iizuka2017globally,
  author    = {Iizuka, Satoshi and Simo-Serra, Edgar and Ishikawa, Hiroshi},
  title     = {Globally and locally consistent image completion},
  journal   = {ACM Transactions on Graphics (TOG)},
  year      = {2017},
  volume    = {36},
  number    = {4},
  pages     = {107},
  file      = {:iizuka2017globally - Globally and locally consistent image completion.pdf:PDF},
  groups    = {Inpainting},
  keywords  = {inpainting},
  owner     = {shehabk},
  publisher = {ACM},
  timestamp = {2018-02-20},
}

@InProceedings{sabour2017dynamic,
  author    = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
  title     = {Dynamic routing between capsules},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  pages     = {3859--3869},
  file      = {:sabour2017dynamic - Dynamic routing between capsules.pdf:PDF},
  groups    = {DL Advancement},
  keywords  = {CapsNet,nips17},
  owner     = {shehabk},
  review    = {Here are some good reads:
1) https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b
2) https://jhui.github.io/2017/11/03/Dynamic-Routing-Between-Capsules/},
  timestamp = {2018.02.22},
}

@Article{hinton2018matrix,
  author    = {Hinton, Geoffrey and Frosst, Nicholas and Sabour, Sara},
  title     = {Matrix capsules with EM routing},
  year      = {2018},
  file      = {:hinton2018matrix - Matrix capsules with EM routing.pdf:PDF},
  groups    = {DL Advancement},
  owner     = {shehabk},
  review    = {Good Reading:
1) https://jhui.github.io/2017/11/14/Matrix-Capsules-with-EM-routing-Capsule-Network/},
  timestamp = {2018.02.22},
}

@InProceedings{strangintroduction,
  author   = {Gilbert Strang},
  title    = {Introduction to Linear Algebra Fourth Edition},
  file     = {:strangintroduction - Introduction to Linear Algebra Fourth Edition.pdf:PDF},
  groups   = {Books},
  keywords = {linear algebra},
}

@InProceedings{brandt2012matrix,
  author   = {Kaare Brandt and Petersen and Michael Syskind and Pedersen},
  title    = {The Matrix Cookbook},
  year     = {2012},
  file     = {:brandt2012matrix - The Matrix Cookbook [ http___matrixcookbook.com.pdf:PDF},
  groups   = {Books},
  keywords = {matrix,cookbook},
}

@InProceedings{terejanu2015csce883,
  author = {Gabriel Terejanu},
  title  = {CSCE883: Machine Learning},
  year   = {2015},
  file   = {:terejanu2015csce883 - CSCE883_ Machine Learning.pdf:PDF},
  groups = {Course Slides},
}

@InProceedings{tong2015csce,
  author = {Yan Tong},
  title  = {CSCE 867: Computer Vision},
  year   = {2015},
  file   = {:tong2015csce - CSCE 867_ Computer Vision.pdf:PDF},
  groups = {Course Slides},
}

@InProceedings{tong2016csce,
  author = {Yan Tong},
  title  = {CSCE 763: Digital Image Processing},
  year   = {2016},
  file   = {:tong2016csce - CSCE 763_ Digital Image Processing.pdf:PDF},
  groups = {Course Slides},
}

@InProceedings{kollercourserapgm,
  author   = {Daphne Koller},
  title    = {Coursera:PGM Slides},
  file     = {:kollercourserapgm - Coursera_PGM Slides.pdf:PDF},
  groups   = {Course Slides},
  keywords = {manual},
}

@InProceedings{larochelleneural,
  author = {Hugo Larochelle},
  title  = {Neural Networks: Hugo Larochelle},
  file   = {:larochelleneural - Neural Networks_ Hugo Larochelle.pdf:PDF},
  groups = {Course Slides},
}

@InProceedings{li2017cs231,
  author = {Fei-Fei Li and \& Justin and Johnson and Serena Yeung},
  title  = {CS231: Spring17},
  year   = {2017},
  file   = {:li2017cs231 - CS231_ Spring17.pdf:PDF},
  groups = {Course Slides},
  review = {Good Reads:
https://www.slideshare.net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-andrew-ng},
}

@InProceedings{rekleitisrobotics,
  author = {Ioannis Rekleitis},
  title  = {Robotics 574},
  file   = {:rekleitisrobotics - Robotics 574.pdf:PDF},
  groups = {Course Slides},
}

@Standard{theory,
  title     = {Theory 551},
  file      = {:default.pdf:PDF},
  groups    = {Course Slides},
  keywords  = {class note},
  owner     = {shehabk},
  timestamp = {2018.02.23},
}

@Book{schapireboosting,
  title  = {Boosting: Foundations and Algorithms},
  author = {Robert E. Schapire, Yoav Freund},
  file   = {:schapireboosting - Boosting_ Foundations and Algorithms.pdf:PDF},
  md5    = {99d47ba2992cf52e799d6fb412f02d1d},
  resid  = {919910},
  size   = {5522793},
  status = {OK},
  type   = {pdf},
}

@InProceedings{systemfacial,
  author   = {System},
  title    = {Facial Action Coding},
  file     = {:systemfacial - Facial Action Coding.pdf:PDF},
  groups   = {AU},
  keywords = {InvGuide},
}

@InProceedings{dhall2016emotiw,
  author       = {Dhall, Abhinav and Goecke, Roland and Joshi, Jyoti and Hoey, Jesse and Gedeon, Tom},
  title        = {Emotiw 2016: Video and group-level emotion recognition challenges},
  booktitle    = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year         = {2016},
  pages        = {427--432},
  organization = {ACM},
  file         = {:dhall2016emotiw - Emotiw 2016_ Video and group-level emotion recognition challenges.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {baseline},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{dhall2015video,
  author       = {Dhall, Abhinav and Ramana Murthy, OV and Goecke, Roland and Joshi, Jyoti and Gedeon, Tom},
  title        = {Video and image based emotion recognition challenges in the wild: Emotiw 2015},
  booktitle    = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
  year         = {2015},
  pages        = {423--426},
  organization = {ACM},
  file         = {:dhall2015video - Video and image based emotion recognition challenges in the wild_ Emotiw 2015.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {baseline},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{dhall2014emotion,
  author       = {Dhall, Abhinav and Goecke, Roland and Joshi, Jyoti and Sikka, Karan and Gedeon, Tom},
  title        = {Emotion recognition in the wild challenge 2014: Baseline, data and protocol},
  booktitle    = {Proceedings of the 16th International Conference on Multimodal Interaction},
  year         = {2014},
  pages        = {461--466},
  organization = {ACM},
  file         = {:dhall2014emotion - Emotion recognition in the wild challenge 2014_ Baseline, data and protocol.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {baseline},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{dhall2013emotion,
  author       = {Dhall, Abhinav and Goecke, Roland and Joshi, Jyoti and Wagner, Michael and Gedeon, Tom},
  title        = {Emotion recognition in the wild challenge 2013},
  booktitle    = {Proceedings of the 15th ACM on International conference on multimodal interaction},
  year         = {2013},
  pages        = {509--516},
  organization = {ACM},
  file         = {:dhall2013emotion - Emotion recognition in the wild challenge 2013.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {baseline},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{yao2015capturing,
  author       = {Yao, Anbang and Shao, Junchao and Ma, Ningning and Chen, Yurong},
  title        = {Capturing au-aware facial features and their latent relations for emotion recognition in the wild},
  booktitle    = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
  year         = {2015},
  pages        = {451--458},
  organization = {ACM},
  file         = {:yao2015capturing - Capturing au-aware facial features and their latent relations for emotion recognition in the wild.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {winner,video based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{kim2015hierarchical,
  author       = {Kim, Bo-Kyeong and Lee, Hwaran and Roh, Jihyeon and Lee, Soo-Young},
  title        = {Hierarchical committee of deep cnns with exponentially-weighted decision fusion for static facial expression recognition},
  booktitle    = {Proceedings of the 2015 ACM on International Conference on Multimodal Interaction},
  year         = {2015},
  pages        = {427--434},
  organization = {ACM},
  file         = {:kim2015hierarchical - Hierarchical committee of deep cnns with exponentially-weighted decision fusion for static facial expression recognition.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {winner,image based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{liu2014combining,
  author       = {Liu, Mengyi and Wang, Ruiping and Li, Shaoxin and Shan, Shiguang and Huang, Zhiwu and Chen, Xilin},
  title        = {Combining multiple kernel methods on riemannian manifold for emotion recognition in the wild},
  booktitle    = {Proceedings of the 16th International Conference on Multimodal Interaction},
  year         = {2014},
  pages        = {494--501},
  organization = {ACM},
  file         = {:liu2014combining - Combining multiple kernel methods on riemannian manifold for emotion recognition in the wild.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {winner},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{dhall2017individual,
  author       = {Dhall, Abhinav and Goecke, Roland and Ghosh, Shreya and Joshi, Jyoti and Hoey, Jesse and Gedeon, Tom},
  title        = {From individual to group-level emotion recognition: EmotiW 5.0},
  booktitle    = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
  year         = {2017},
  pages        = {524--528},
  organization = {ACM},
  file         = {:dhall2017individual - From individual to group-level emotion recognition_ EmotiW 5.0.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {baseline},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{hu2017learning,
  author       = {Hu, Ping and Cai, Dongqi and Wang, Shandong and Yao, Anbang and Chen, Yurong},
  title        = {Learning supervised scoring ensemble for emotion recognition in the wild},
  booktitle    = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
  year         = {2017},
  pages        = {553--560},
  organization = {ACM},
  file         = {:hu2017learning - Learning supervised scoring ensemble for emotion recognition in the wild.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {winner, audio-video},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@Article{knyazev2017convolutional,
  author    = {Knyazev, Boris and Shvetsov, Roman and Efremova, Natalia and Kuharenko, Artem},
  title     = {Convolutional neural networks pretrained on large face recognition datasets for emotion classification from video},
  journal   = {arXiv preprint arXiv:1711.04598},
  year      = {2017},
  file      = {:knyazev2017convolutional - Convolutional neural networks pretrained on large face recognition datasets for emotion classification from video.pdf:PDF},
  groups    = {EmotiW},
  keywords  = {runner-up, audio-video},
  owner     = {shehabk},
  timestamp = {2018.03.19},
}

@InProceedings{vielzeuf2017temporal,
  author       = {Vielzeuf, Valentin and Pateux, St{\'e}phane and Jurie, Fr{\'e}d{\'e}ric},
  title        = {Temporal multimodal fusion for video emotion classification in the wild},
  booktitle    = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
  year         = {2017},
  pages        = {569--576},
  organization = {ACM},
  file         = {:vielzeuf2017temporal - Temporal multimodal fusion for video emotion classification in the wild.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {3rd, audio-video},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{tan2017group,
  author       = {Tan, Lianzhi and Zhang, Kaipeng and Wang, Kai and Zeng, Xiaoxing and Peng, Xiaojiang and Qiao, Yu},
  title        = {Group emotion recognition with individual facial emotion CNNs and global image based CNNs},
  booktitle    = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
  year         = {2017},
  pages        = {549--552},
  organization = {ACM},
  file         = {:tan2017group - Group emotion recognition with individual facial emotion CNNs and global image based CNNs.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {winner, group-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{guo2017group,
  author       = {Guo, Xin and Polan{\'\i}a, Luisa F and Barner, Kenneth E},
  title        = {Group-level emotion recognition using deep models on image scene, faces, and skeletons},
  booktitle    = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
  year         = {2017},
  pages        = {603--608},
  organization = {ACM},
  file         = {:guo2017group - Group-level emotion recognition using deep models on image scene, faces, and skeletons.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {runner-up,group-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{wei2017new,
  author       = {Wei, Qinglan and Zhao, Yijia and Xu, Qihua and Li, Liandong and He, Jun and Yu, Lejun and Sun, Bo},
  title        = {A new deep-learning framework for group emotion recognition},
  booktitle    = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
  year         = {2017},
  pages        = {587--592},
  organization = {ACM},
  file         = {:wei2017new - A new deep-learning framework for group emotion recognition.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {3rd,group-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{li2016happiness,
  author       = {Li, Jianshu and Roy, Sujoy and Feng, Jiashi and Sim, Terence},
  title        = {Happiness level prediction with sequential inputs via multiple regressions},
  booktitle    = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year         = {2016},
  pages        = {487--493},
  organization = {ACM},
  file         = {:li2016happiness - Happiness level prediction with sequential inputs via multiple regressions.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {winner,group-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{vonikakis2016group,
  author       = {Vonikakis, Vassilios and Yazici, Yasin and Nguyen, Viet Dung and Winkler, Stefan},
  title        = {Group happiness assessment using geometric features and dataset balancing},
  booktitle    = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year         = {2016},
  pages        = {479--486},
  organization = {ACM},
  file         = {:vonikakis2016group - Group happiness assessment using geometric features and dataset balancing.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {runner-up,grpup-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{sun2016lstm,
  author       = {Sun, Bo and Wei, Qinglan and Li, Liandong and Xu, Qihua and He, Jun and Yu, Lejun},
  title        = {LSTM for dynamic emotion and group emotion recognition in the wild},
  booktitle    = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year         = {2016},
  pages        = {451--457},
  organization = {ACM},
  file         = {:sun2016lstm - LSTM for dynamic emotion and group emotion recognition in the wild.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {3rd,group-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{fan2016video,
  author       = {Fan, Yin and Lu, Xiangju and Li, Dian and Liu, Yuanliu},
  title        = {Video-based emotion recognition using CNN-RNN and C3D hybrid networks},
  booktitle    = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year         = {2016},
  pages        = {445--450},
  organization = {ACM},
  file         = {:fan2016video - Video-based emotion recognition using CNN-RNN and C3D hybrid networks.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {winner,video-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{yao2016holonet,
  author       = {Yao, Anbang and Cai, Dongqi and Hu, Ping and Wang, Shandong and Sha, Liang and Chen, Yurong},
  title        = {HoloNet: towards robust emotion recognition in the wild},
  booktitle    = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year         = {2016},
  pages        = {472--478},
  organization = {ACM},
  file         = {:yao2016holonet - HoloNet_ towards robust emotion recognition in the wild.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {runner-up,video-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{bargal2016emotion,
  author       = {Bargal, Sarah Adel and Barsoum, Emad and Ferrer, Cristian Canton and Zhang, Cha},
  title        = {Emotion recognition in the wild from videos using images},
  booktitle    = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year         = {2016},
  pages        = {433--436},
  organization = {ACM},
  file         = {:bargal2016emotion - Emotion recognition in the wild from videos using images.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {3rd,video-based},
  owner        = {shehabk},
  timestamp    = {2018.03.19},
}

@InProceedings{Yan:2016:MFE:2993148.2997630,
  author    = {Yan, Jingwei and Zheng, Wenming and Cui, Zhen and Tang, Chuangao and Zhang, Tong and Zong, Yuan and Sun, Ning},
  title     = {Multi-clue Fusion for Emotion Recognition in the Wild},
  booktitle = {Proceedings of the 18th ACM International Conference on Multimodal Interaction},
  year      = {2016},
  series    = {ICMI 2016},
  pages     = {458--463},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2997630},
  doi       = {10.1145/2993148.2997630},
  file      = {:Yan_2016_MFE_2993148.2997630 - Multi-clue Fusion for Emotion Recognition in the Wild.pdf:PDF},
  groups    = {EmotiW},
  isbn      = {978-1-4503-4556-9},
  keywords  = {3rd,video-based},
  location  = {Tokyo, Japan},
  numpages  = {6},
  owner     = {shehabk},
  timestamp = {2018.03.19},
  url       = {http://doi.acm.org/10.1145/2993148.2997630},
}

@InCollection{rasmussen2004gaussian,
  author    = {Rasmussen, Carl Edward},
  title     = {Gaussian processes in machine learning},
  booktitle = {Advanced lectures on machine learning},
  publisher = {Springer},
  year      = {2004},
  pages     = {63--71},
  file      = {:rasmussen2004gaussian - Gaussian processes in machine learning.pdf:PDF},
  groups    = {Books},
  keywords  = {gaussian processes},
  owner     = {shehabk},
  timestamp = {2018-02-26},
}

@Standard{explaining,
  title     = {Explaining AdaBoost},
  file      = {:explaining - Explaining AdaBoost.pdf:PDF},
  groups    = {Tutorials},
  owner     = {shehabk},
  review    = {Others:
http://www.cs.man.ac.uk/~stapenr5/boosting.pdf (Seems very good)},
  timestamp = {2018-02-26},
}

@InProceedings{dhall2015more,
  author       = {Dhall, Abhinav and Joshi, Jyoti and Sikka, Karan and Goecke, Roland and Sebe, Nicu},
  title        = {The more the merrier: Analysing the affect of a group of people in images},
  booktitle    = {Automatic Face and Gesture Recognition (FG), 2015 11th IEEE International Conference and Workshops on},
  year         = {2015},
  volume       = {1},
  pages        = {1--8},
  organization = {IEEE},
  file         = {:dhall2015more - The more the merrier_ Analysing the affect of a group of people in images.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {reference,group-based},
  owner        = {shehabk},
  timestamp    = {2018.03.20},
}

@InProceedings{dhall2017individual,
  author       = {Dhall, Abhinav and Goecke, Roland and Ghosh, Shreya and Joshi, Jyoti and Hoey, Jesse and Gedeon, Tom},
  title        = {From individual to group-level emotion recognition: EmotiW 5.0},
  booktitle    = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
  year         = {2017},
  pages        = {524--528},
  organization = {ACM},
  file         = {:dhall2017individual - From individual to group-level emotion recognition_ EmotiW 5.0.pdf:PDF},
  groups       = {EmotiW},
  keywords     = {reference,group-based},
  owner        = {shehabk},
  timestamp    = {2018.03.20},
}

@InProceedings{dhall2015morea,
  author   = {Abhinav Dhall and Jyoti Joshi and Karan Sikka and Roland Goecke and Nicu Sebe},
  title    = {The More the Merrier: Analysing the Affect of a Group of People in Images},
  year     = {2015},
  file     = {:dhall2015morea - The More the Merrier_ Analysing the Affect of a Group of People in Images.pdf:PDF},
  groups   = {EmotiW},
  keywords = {reference,group-based,lecture},
}

@InProceedings{rosecsce587,
  author = {rose},
  title  = {CSCE:587 Big Data},
  file   = {:rosecsce587 - CSCE_587 Big Data.pdf:PDF},
  groups = {Course Slides},
}

@InProceedings{by2015propagated,
  author   = {Youjie Zhou},
  title    = {Propagated Image Segmentation Using Edge-Weighted Centroidal Voronoi Tessellation Based Methods},
  year     = {2015},
  file     = {:by2015propagated - Propagated Image Segmentation Using Edge-Weighted Centroidal Voronoi Tessellation Based Methods.pdf:PDF},
  groups   = {segmentation},
  keywords = {thesis},
}

@InProceedings{by20133d,
  author   = {Yu Cao},
  title    = {3D GRAIN SEGMENTATION IN SUPERALLOY IMAGES USING MULTICHANNEL EDGE-WEIGHTED CENTROIDAL VORONOI TESSELLATION BASED METHODS},
  year     = {2013},
  file     = {:by20133d - 3D GRAIN SEGMENTATION IN SUPERALLOY IMAGES USING MULTICHANNEL EDGE-WEIGHTED CENTROIDAL VORONOI TESSELLATION BASED METHODS.pdf:PDF},
  groups   = {segmentation},
  keywords = {thesis},
}

@Article{garcia2017review,
  author    = {Garcia-Garcia, Alberto and Orts-Escolano, Sergio and Oprea, Sergiu and Villena-Martinez, Victor and Garcia-Rodriguez, Jose},
  title     = {A review on deep learning techniques applied to semantic segmentation},
  journal   = {arXiv preprint arXiv:1704.06857},
  year      = {2017},
  file      = {:garcia2017review - A review on deep learning techniques applied to semantic segmentation.pdf:PDF},
  groups    = {segmentation},
  owner     = {shehabk},
  timestamp = {2018.03.28},
}

@Book{halimcompetative,
  title     = {Competative Programiing 3},
  author    = {Steven Halim},
  file      = {:halimcompetative - Competative Programiing 3.pdf:PDF},
  groups    = {Books},
  owner     = {shehabk},
  timestamp = {2018.04.17},
}

@Article{shao2018deep,
  author    = {Shao, Zhiwen and Liu, Zhilei and Cai, Jianfei and Ma, Lizhuang},
  title     = {Deep Adaptive Attention for Joint Facial Action Unit Detection and Face Alignment},
  journal   = {arXiv preprint arXiv:1803.05588},
  year      = {2018},
  file      = {:shao2018deep - Deep Adaptive Attention for Joint Facial Action Unit Detection and Face Alignment.pdf:PDF},
  groups    = {AU},
  owner     = {shehabk},
  review    = {This paper uses attention.},
  timestamp = {2018.05.08},
}

@InProceedings{rossum2012python,
  author = {Guido van Rossum and Fred L. Drake and Jr and editor},
  title  = {The Python Language Reference Release},
  year   = {2012},
  file   = {:rossum2012python - The Python Language Reference Release.pdf:PDF},
  groups = {Python},
}

@InProceedings{rossum2012pythona,
  author = {Guido van Rossum and Fred L. Drake and Jr and editor},
  title  = {The Python Library Reference Release},
  year   = {2012},
  file   = {:rossum2012pythona - The Python Library Reference Release.pdf:PDF},
  groups = {Python},
}

@InProceedings{course,
  title  = {Service Oriented Architecture Course Notes},
  file   = {:Service-Oriented-Architecture-Courese-Notes.pdf:PDF},
  groups = {Design Patterns and Software Arhitecture},
}

@InProceedings{coursea,
  title  = {Object Oriented Design Course Notes},
  file   = {:Object-Oriented-Design-Course-Notes.pdf:PDF},
  groups = {Design Patterns and Software Arhitecture},
}

@InProceedings{courseb,
  title  = {Design Pattern Course Notes},
  file   = {:Desigh-Patterns-Course-Notes.pdf:PDF},
  groups = {Design Patterns and Software Arhitecture},
}

@InProceedings{???in??object-oriented??designcourse,
  author = {abstract?? -? ? ?in ? ?object-oriented? ?design and ? ?a? ?class? ?that? ?cannot? b? e? ?instantiated? ?directly and ? ?but? ?must? b? e and subclassed.? ?It and ?can? ?also and ?apply? ?to and ?a? ?method and ? ?or and a? ttribute ?of and ?a? ?class. and abstract? ?data and ?types?? and ?data? ?types and ?that? ?are and d? efined ?by and ?the? ?their and b? ehaviour ?as and ?opposed? ?to and ?their and structure.? ?Defined and ? ?by and t? he ?developer and ?rather? ?than and ?the? ?programming and ?language and access? m odifiers and ? ?keywords and ?that? ?control and ?which? ?other and ? ?classes and ?can? ?access and ?a and ?variable? ?or and ?method and in? ?a? ?class.? ?These? ?include ? ??public and ? ?protected and ? ?private and ? a?? nd? ?no? ?keyword and ? ?sometimes? ?called and default?. and abstraction? ??-? ?the? ?act? ?of? ?simplifying? ?a? ?concept? i? n? ?context.? ?In? ?object-oriented? ?design and ? ?it? ?is? ?the and simplification? ?of and ?the? ?real and ?world? ?entity and ?into? ?its and ?most? ?important and ?attributes? ?and and ?behaviours? ?for and ? ?the and purpose? ?of and ?the? ?software. and attribute?? -? ? ?a? ?property? ?that? ?object? ?of? ?a? ?class? ?must? ?have and ? ?even? ?though ? ?their? ?values? ?may? ?be and different.? ?For? ?example and ? ?two? ?student? ?objects? ?each? ?have? ?a? ?grade? ?attribute and ? ?even? ?though? ?one? ?has and an? '?A and ?and? ?the and ?other? ?has and ?a? '?B.' and behaviours? and ?the? a ctions ?that and ? ?an and o? bject and ?can? ?take and boundary? ?object? ??-? ?an? o? bject ? ?whose? ?role? ?is? t? o? ?interface ? ?with? ?an? ?external? ?component and ? ?such? ?as? ?a and user? ?or and ?an? ?adjacent and s? ystem},
  title  = {C1 Glossary},
  file   = {:C1-Glossary.pdf:PDF},
  groups = {Design Patterns and Software Arhitecture},
}

@InProceedings{abstract?superclasscourse,
  author = {abstract? s uperclass and ?-? a and ?class? w hich and ?must and ?have? s ubclasses ?in and o? rder and ?to? ?be and ?instantiated. and Adapter? p attern and ?-? a and ?design? p attern ?that and ? ?connects and ?two? ?incompatible and i? nterfaces ?by and f? itting ?between and them? ?and and p? roviding a and ?compatible and ?interface and ?to? ?both. and Agile? d evelopment and ?-? and ?a and ?family and ?of? s oftware and ?development? ?methodologies and ? ?that and ?encourage and adaptivity and ? ?cross-functional? c? ollaboration and ? ?evolutionary? ?development and ? ?early? ?delivery and ? ?and and continuous? ?improvement. and Anti-Pattern?? and ? ?a and ? ?commonly-encountered and ?attempted? s olution and ?to? ?a and ? ?problem and w? hich and ?is and counterproductive? o r and ?ineffective. and behavioural? ?patterns and ? and d? esign p atterns and ?that? f ocus ?on and h? ow o bjects ?distribute and ? ?work. and boundary? ?object and ?? and a? n and ?object and ?which? ?interfaces and ?with and ?objects? o utside ?the and ?current? ?system and ?or? w ith and users. and Chain? o f and ?Responsibility? p attern and ? ?a and ? ?behavioural and p? attern f or a llowing and ?multiple? ?entities and t? o and ?handle and requests. and code and ?reuse? and u? sing and ?existing? c ode ?to and b? uild and ?new and ?software. and code and ?smell? and a? and ?symptom and ?of? ?bad and ?code.},
  title  = {C2-Glossary},
  file   = {:C2-Glossary.pdf:PDF},
  groups = {Design Patterns and Software Arhitecture},
}

@InProceedings{aggregation?course,
  author = {aggregation? and ?-? p utting ?objects and ?or? o ther and ?components and ?together and binding? and 1)?? and ? ?the and ? ?act and ?of? p rogramming and ?a? ?service and r? equester t o ?interact and w? ith ?a and ? ?service and p? rovider.? C and an and be and ?done? p rogrammatically o r and ?manually? ?by and ?using? ?the and ?WSDL and ?description. and binding ? ?(2) ?? ?-? i? n ? ?WSDL and ? ?the? b? indings ? ?section? ?gives? ?detail? ?about? t? he? p? rotocols? a? nd? ?standards ? ?that and are? ?mapped and t? o and ?the and ?interaction. and BPEL/WS-BPEL?? and ?a and ?design and ?language? ?for and c? omposing w eb ?services. and ?Stands and ?for? ?Business and P? rocess and Execution and ?Language. and Composing? ?Object and ?principle?? and ? ?a and f? orm ?of and ?aggregation? ?in and O? O and ? ?in and ?which? t he d esired b ehaviour i s and obtained? ?by and c? ombining o bjects and composition? and ?-? c reating and ?a? n ew s ervice b y and ?combining and ?other? s ervices and coordination?? and ? ?using and ?two? ?or and m? ore ?services and ?in? ?conjunction and DOCTYPE?? and ? ?is and t? he f irst ?line and ? ?in and ?any? ?HTML and ? ?file.It? i s and ?what? ?denotes and t? o and ?the and ?browser and ?that? t he f ile ?is and HTML and eXtensible? ?Markup and ?Language?? ?or and ??XML?? and ? ?is and ?a and ?markup? ?language and t? hat ?was and m? eant and ?to? ?store and a? nd and transport? ?data.},
  title  = {C4-Glossary},
  file   = {:C4-Glossary.pdf:PDF},
  groups = {Design Patterns and Software Arhitecture},
}

@Article{tulyakov2017mocogan,
  author    = {Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
  title     = {Mocogan: Decomposing motion and content for video generation},
  journal   = {arXiv preprint arXiv:1707.04993},
  year      = {2017},
  file      = {:tulyakov2017mocogan - Mocogan_ Decomposing motion and content for video generation.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  timestamp = {2018.06.18},
}

@InProceedings{oh2015action,
  author    = {Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard L and Singh, Satinder},
  title     = {Action-conditional video prediction using deep networks in atari games},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2015},
  pages     = {2863--2871},
  file      = {:oh2015action - Action-conditional video prediction using deep networks in atari games.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  review    = {This one is not using Gan for generating images. Using Reinforcement Learning. But very similar in lstm modelling.},
  timestamp = {2018.06.18},
}

@InProceedings{srivastava2015unsupervised,
  author    = {Srivastava, Nitish and Mansimov, Elman and Salakhudinov, Ruslan},
  title     = {Unsupervised learning of video representations using lstms},
  booktitle = {International conference on machine learning},
  year      = {2015},
  pages     = {843--852},
  file      = {:srivastava2015unsupervised - Unsupervised learning of video representations using lstms.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  timestamp = {2018.06.18},
}

@Article{mathieu2015deep,
  author    = {Mathieu, Michael and Couprie, Camille and LeCun, Yann},
  title     = {Deep multi-scale video prediction beyond mean square error},
  journal   = {arXiv preprint arXiv:1511.05440},
  year      = {2015},
  file      = {:mathieu2015deep - Deep multi-scale video prediction beyond mean square error.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  review    = {This paper do utilizes gan and a multiscale cnn. They introduces the gradient difference loss},
  timestamp = {2018.06.18},
}

@Article{kalchbrenner2016video,
  author    = {Kalchbrenner, Nal and Oord, Aaron van den and Simonyan, Karen and Danihelka, Ivo and Vinyals, Oriol and Graves, Alex and Kavukcuoglu, Koray},
  title     = {Video pixel networks},
  journal   = {arXiv preprint arXiv:1610.00527},
  year      = {2016},
  file      = {:kalchbrenner2016video - Video pixel networks.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  review    = {Looks hard. Based on Pixel CNN},
  timestamp = {2018.06.18},
}

@InProceedings{finn2016unsupervised,
  author    = {Finn, Chelsea and Goodfellow, Ian and Levine, Sergey},
  title     = {Unsupervised learning for physical interaction through video prediction},
  booktitle = {Advances in neural information processing systems},
  year      = {2016},
  pages     = {64--72},
  file      = {:finn2016unsupervised - Unsupervised learning for physical interaction through video prediction.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  review    = {Has Good Fellow in it. It kind of uses convolutional lstm to model the dynamics in every layer.},
  timestamp = {2018.06.18},
}

@Article{van2017transformation,
  author    = {Van Amersfoort, Joost and Kannan, Anitha and Ranzato, Marc'Aurelio and Szlam, Arthur and Tran, Du and Chintala, Soumith},
  title     = {Transformation-based models of video sequences},
  journal   = {arXiv preprint arXiv:1701.08435},
  year      = {2017},
  file      = {:van2017transformation - Transformation-based models of video sequences.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  review    = {This paper tries to find affine transformation for overlapping patches and then somehow combines them to form the frame.},
  timestamp = {2018.06.18},
}

@InProceedings{xue2016probabilistic,
  author    = {Xue, T and Wu, J and Bouman, K and Freeman, B},
  title     = {Probabilistic modeling of future frames from a single image},
  booktitle = {NIPS},
  year      = {2016},
  file      = {:xue2016probabilistic - Probabilistic modeling of future frames from a single image.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  review    = {This kind of models the distriibution of possible next frames in some probabilistic way.},
  timestamp = {2018.06.18},
}

@InProceedings{denton2017unsupervised,
  author    = {Denton, Emily L and others},
  title     = {Unsupervised learning of disentangled representations from video},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  pages     = {4417--4426},
  file      = {:denton2017unsupervised - Unsupervised learning of disentangled representations from video.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  timestamp = {2018.06.18},
}

@Article{villegas2017decomposing,
  author    = {Villegas, Ruben and Yang, Jimei and Hong, Seunghoon and Lin, Xunyu and Lee, Honglak},
  title     = {Decomposing motion and content for natural video sequence prediction},
  journal   = {arXiv preprint arXiv:1706.08033},
  year      = {2017},
  file      = {:villegas2017decomposing - Decomposing motion and content for natural video sequence prediction.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  timestamp = {2018.06.18},
}

@Article{lideep,
  author    = {Shan Li, Weihong Deng?},
  title     = {Deep Facial Expression Recognition: A Survey},
  file      = {:lideep - Deep Facial Expression Recognition_ A Survey.pdf:PDF},
  groups    = {paper review},
  owner     = {shehabk},
  timestamp = {2018.06.19},
}

@InProceedings{bmvc2018joint,
  author   = {BMVC 005},
  title    = {JOINT AU LOCALISATION AND INTENSITY ESTIMATION},
  year     = {2018},
  abstract = {010
011 This paper proposes a supervised learning approach to jointly perform facial Action Unit
012 (AU) localisation and intensity estimation. Contrary to previous works that try to learn},
  file     = {:bmvc2018joint - JOINT AU LOCALISATION AND INTENSITY ESTIMATION.pdf:PDF},
  groups   = {paper review},
}

@InProceedings{bradski4886learning,
  author = {Gary Bradski and Adrian Kaehler},
  title  = {Learning OpenCV},
  year   = {4886},
  file   = {:bradski4886learning - Learning OpenCV.pdf:PDF},
  groups = {opencv},
}

@Article{kaehlerpractical,
  author    = {Adrian Kaehler},
  title     = {Practical Python and OpenCV},
  file      = {:kaehlerpractical - Practical Python and OpenCV.pdf:PDF},
  groups    = {opencv},
  owner     = {shehabk},
  timestamp = {2018.07.09},
}

@Article{kaehlercase,
  author    = {Adrian Kaehler},
  title     = {Case Studies},
  file      = {:kaehlercase - Case Studies.pdf:PDF},
  groups    = {opencv},
  owner     = {shehabk},
  timestamp = {2018.07.09},
}

@Misc{minichino2015learning,
  author    = {Minichino, Joe and Howse, Joseph},
  title     = {Learning OpenCV 3 Computer Vision with Python Second Edition},
  month     = sep,
  year      = {2015},
  file      = {Joe Minichino, Joseph Howse - Learning OpenCV 3 Computer Vision with Python (2015, Packt Publishing).pdf:minichino2015learning - Learning OpenCV 3 Computer Vision with Python Second Edition.pdf:PDF},
  groups    = {opencv},
  publisher = {Packt Publishing},
}

@Misc{smithcython,
  author = {Kurt W. Smith},
  title  = {Cython: A Guide for Python Programmers},
  file   = {Cython-A-Guide-for-Python-Programmers.pdf:smithcython - Cython_ A Guide for Python Programmers.pdf:PDF},
  groups = {Python},
}

@InProceedings{Bai_2018_CVPR,
  author    = {Bai, Yancheng and Zhang, Yongqiang and Ding, Mingli and Ghanem, Bernard},
  title     = {Finding Tiny Faces in the Wild With Generative Adversarial Network},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Bai_2018_CVPR - Finding Tiny Faces in the Wild With Generative Adversarial Network.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Yang_2018_CVPR,
  author    = {Yang, Hongyu and Huang, Di and Wang, Yunhong and Jain, Anil K.},
  title     = {Learning Face Age Progression: A Pyramid Architecture of GANs},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Yang_2018_CVPR - Learning Face Age Progression_ A Pyramid Architecture of GANs.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Chang_2018_CVPR,
  author    = {Chang, Huiwen and Lu, Jingwan and Yu, Fisher and Finkelstein, Adam},
  title     = {PairedCycleGAN: Asymmetric Style Transfer for Applying and Removing Makeup},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Chang_2018_CVPR - PairedCycleGAN_ Asymmetric Style Transfer for Applying and Removing Makeup.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Mueller_2018_CVPR,
  author    = {Mueller, Franziska and Bernard, Florian and Sotnychenko, Oleksandr and Mehta, Dushyant and Sridhar, Srinath and Casas, Dan and Theobalt, Christian},
  title     = {GANerated Hands for Real-Time 3D Hand Tracking From Monocular RGB},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Mueller_2018_CVPR - GANerated Hands for Real-Time 3D Hand Tracking From Monocular RGB.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Ma_2018_CVPR,
  author    = {Ma, Liqian and Sun, Qianru and Georgoulis, Stamatios and Van Gool, Luc and Schiele, Bernt and Fritz, Mario},
  title     = {Disentangled Person Image Generation},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Ma_2018_CVPR - Disentangled Person Image Generation.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Bulat_2018_CVPR,
  author    = {Bulat, Adrian and Tzimiropoulos, Georgios},
  title     = {Super-FAN: Integrated Facial Landmark Localization and Super-Resolution of Real-World Low Resolution Faces in Arbitrary Poses With GANs},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Bulat_2018_CVPR - Super-FAN_ Integrated Facial Landmark Localization and Super-Resolution of Real-World Low Resolution Faces in Arbitrary Poses With GANs.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Si_2018_CVPR,
  author    = {Si, Chenyang and Wang, Wei and Wang, Liang and Tan, Tieniu},
  title     = {Multistage Adversarial Losses for Pose-Based Human Image Synthesis},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Si_2018_CVPR - Multistage Adversarial Losses for Pose-Based Human Image Synthesis.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Dong_2018_CVPR,
  author    = {Dong, Xuanyi and Yu, Shoou-I and Weng, Xinshuo and Wei, Shih-En and Yang, Yi and Sheikh, Yaser},
  title     = {Supervision-by-Registration: An Unsupervised Approach to Improve the Precision of Facial Landmark Detectors},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Dong_2018_CVPR - Supervision-by-Registration_ An Unsupervised Approach to Improve the Precision of Facial Landmark Detectors.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Li_2018_CVPR,
  author    = {Li, Shuang and Bak, Slawomir and Carr, Peter and Wang, Xiaogang},
  title     = {Diversity Regularized Spatiotemporal Attention for Video-Based Person Re-Identification},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Li_2018_CVPR - Diversity Regularized Spatiotemporal Attention for Video-Based Person Re-Identification.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Dong_2018_CVPR,
  author    = {Dong, Xuanyi and Yan, Yan and Ouyang, Wanli and Yang, Yi},
  title     = {Style Aggregated Network for Facial Landmark Detection},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Dong_2018_CVPR - Style Aggregated Network for Facial Landmark Detection.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Wang_2018_CVPR,
  author    = {Wang, Kang and Zhao, Rui and Ji, Qiang},
  title     = {A Hierarchical Generative Model for Eye Image Synthesis and Eye Gaze Estimation},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Wang_2018_CVPR - A Hierarchical Generative Model for Eye Image Synthesis and Eye Gaze Estimation.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Baradel_2018_CVPR,
  author    = {Baradel, Fabien and Wolf, Christian and Mille, Julien and Taylor, Graham W.},
  title     = {Glimpse Clouds: Human Activity Recognition From Unstructured Feature Points},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Baradel_2018_CVPR - Glimpse Clouds_ Human Activity Recognition From Unstructured Feature Points.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Zhang_2018_CVPR,
  author    = {Zhang, Xiaoning and Wang, Tiantian and Qi, Jinqing and Lu, Huchuan and Wang, Gang},
  title     = {Progressive Attention Guided Recurrent Network for Salient Object Detection},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Zhang_2018_CVPR - Progressive Attention Guided Recurrent Network for Salient Object Detection.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Mopuri_2018_CVPR,
  author    = {Reddy Mopuri, Konda and Ojha, Utkarsh and Garg, Utsav and Venkatesh Babu, R.},
  title     = {NAG: Network for Adversary Generation},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Mopuri_2018_CVPR - NAG_ Network for Adversary Generation.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Shen_2018_CVPR,
  author    = {Shen, Yujun and Luo, Ping and Yan, Junjie and Wang, Xiaogang and Tang, Xiaoou},
  title     = {FaceID-GAN: Learning a Symmetry Three-Player GAN for Identity-Preserving Face Synthesis},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Shen_2018_CVPR - FaceID-GAN_ Learning a Symmetry Three-Player GAN for Identity-Preserving Face Synthesis.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Kossaifi_2018_CVPR,
  author    = {Kossaifi, Jean and Tran, Linh and Panagakis, Yannis and Pantic, Maja},
  title     = {GAGAN: Geometry-Aware Generative Adversarial Networks},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Kossaifi_2018_CVPR - GAGAN_ Geometry-Aware Generative Adversarial Networks.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@InProceedings{Xu_2018_CVPR,
  author    = {Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},
  title     = {AttnGAN: Fine-Grained Text to Image Generation With Attentional Generative Adversarial Networks},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2018},
  month     = {June},
  file      = {:Xu_2018_CVPR - AttnGAN_ Fine-Grained Text to Image Generation With Attentional Generative Adversarial Networks.pdf:PDF},
  groups    = {cvpr18},
  owner     = {shehabk},
  timestamp = {2018.07.13},
}

@Article{cai2017deep,
  author    = {Cai, Haoye and Bai, Chunyan and Tai, Yu-Wing and Tang, Chi-Keung},
  title     = {Deep Video Generation, Prediction and Completion of Human Action Sequences},
  journal   = {arXiv preprint arXiv:1711.08682},
  year      = {2017},
  file      = {:cai2017deep - Deep Video Generation, Prediction and Completion of Human Action Sequences.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  review    = {Used LSTM as discriminator. Very good paper to read.},
  timestamp = {2018.07.16},
}

@Misc{szeliskicomputer,
  author   = {Richard Szeliski},
  title    = {Computer Vision: Algorithms and Applications},
  abstract = {Computer vision},
  file     = {Computer_Vision_SzeliskiBook_20100903_draft.pdf:szeliskicomputer - Computer Vision_ Algorithms and Applications.pdf:PDF},
  groups   = {Books},
  keywords = {cv},
}

@Misc{kollerprobabilistic,
  author   = {Daphne Koller and Nir Friedman},
  title    = {Probabilistic Graphical Models: Principles and Techniques},
  file     = {(Adaptive computation and machine learning) Daphne Koller_ Nir Friedman -Probabilistic graphical models _ principles and techniques-MIT Press (2009).pdf:kollerprobabilistic - Probabilistic Graphical Models_ Principles and Techniques.pdf:PDF},
  groups   = {Books},
  keywords = {pgm},
}

@Misc{gonzalezdigital,
  author = {Gonzalez},
  title  = {Digital Image Processing},
  file   = {Digital_Image_Processing_GONZALEZ.pdf:gonzalezdigital - Digital Image Processing.pdf:PDF},
  groups = {Books},
}

@Misc{dip3emanualmasterfiledvi,
  title  = {DIP_3E_Manual_Master_File.dvi},
  file   = {DIP3E_Complete_Manual.pdf:/media/shehabk/D_DRIVE/study_at_usc/usc_materials/Books/DIP3E_Complete_Manual.pdf:PDF},
  groups = {Books},
}

@TechReport{laakmann2005fourth,
  author = {Gayle Laakmann},
  title  = {FOURTH CRACKING THE EDITION},
  year   = {2005},
  number = {Questions},
  doi    = {ng},
  file   = {:laakmann2005fourth - FOURTH CRACKING THE EDITION.pdf:PDF},
  groups = {Books},
}

@Misc{xiangschaums,
  author = {By Zhigang Xiang, Roy A. Plastock},
  title  = {Schaum's outline of theory and problems of computer graphics},
  file   = {Computer_Graphics.pdf:xiangschaums - Schaum's outline of theory and problems of computer graphics.pdf:PDF},
  groups = {Books},
}

@InProceedings{learningpython,
  author = {Machine Learning and Deep Learning and with Python and scikit-learn and TensorFlow},
  title  = {Python Machine Learning Second Edition},
  file   = {:learningpython - Python Machine Learning Second Edition.pdf:PDF},
  groups = {Python},
  review = {code: https://github.com/rasbt/python-machine-learning-book-2nd-edition},
}

@InProceedings{vondrick2016generating,
  author    = {Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  title     = {Generating videos with scene dynamics},
  booktitle = {Advances In Neural Information Processing Systems},
  year      = {2016},
  pages     = {613--621},
  file      = {:vondrick2016generating - Generating videos with scene dynamics.pdf:PDF},
  groups    = {Dynamic Gan},
  owner     = {shehabk},
  timestamp = {2018.07.26},
}

@Article{pumarola2018ganimation,
  author      = {Albert Pumarola and Antonio Agudo and Aleix M. Martinez and Alberto Sanfeliu and Francesc Moreno-Noguer},
  title       = {GANimation: Anatomically-aware Facial Animation from a Single Image},
  abstract    = {Recent advances in Generative Adversarial Networks (GANs) have shown impressive results for task of facial expression synthesis. The most successful architecture is StarGAN, that conditions GANs generation process with images of a specific domain, namely a set of images of persons sharing the same expression. While effective, this approach can only generate a discrete number of expressions, determined by the content of the dataset. To address this limitation, in this paper, we introduce a novel GAN conditioning scheme based on Action Units (AU) annotations, which describes in a continuous manifold the anatomical facial movements defining a human expression. Our approach allows controlling the magnitude of activation of each AU and combine several of them. Additionally, we propose a fully unsupervised strategy to train the model, that only requires images annotated with their activated AUs, and exploit attention mechanisms that make our network robust to changing backgrounds and lighting conditions. Extensive evaluation show that our approach goes beyond competing conditional generators both in the capability to synthesize a much wider range of expressions ruled by anatomically feasible muscle movements, as in the capacity of dealing with images in the wild.},
  date        = {2018-07-24},
  eprint      = {1807.09251v1},
  eprintclass = {cs.CV},
  eprinttype  = {arXiv},
  file        = {:pumarola2018ganimation - GANimation_ Anatomically-aware Facial Animation from a Single Image.pdf:PDF},
  groups      = {Dynamic Gan},
  keywords    = {cs.CV},
  owner       = {shehabk},
  timestamp   = {2018.07.26},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:AU\;0\;;
1 ExplicitGroup:MyGroup\;0\;;
1 ExplicitGroup:Expression\;0\;;
1 ExplicitGroup:Generative Models\;0\;;
2 ExplicitGroup:Gan Papers\;0\;;
3 ExplicitGroup:Image Translation GAN\;0\;;
3 ExplicitGroup:Face Synthesis GAN\;0\;;
3 ExplicitGroup:Tutorials GAN\;0\;;
3 ExplicitGroup:Theory GAN\;0\;;
3 ExplicitGroup:Conditional Adversarial\;0\;;
3 ExplicitGroup:Inpainting\;0\;;
3 ExplicitGroup:High Quality Image Generation\;0\;;
3 ExplicitGroup:Unlclassified\;0\;;
1 ExplicitGroup:Books\;0\;;
1 ExplicitGroup:paper review\;0\;;
1 ExplicitGroup:DL Advancement\;0\;;
1 ExplicitGroup:CNN Classic\;0\;;
1 ExplicitGroup:Course Slides\;0\;;
1 ExplicitGroup:EmotiW\;0\;;
1 ExplicitGroup:segmentation\;0\;;
1 ExplicitGroup:Scene\;0\;;
1 ExplicitGroup:Python\;0\;;
1 ExplicitGroup:Design Patterns and Software Arhitecture\;0\;;
1 ExplicitGroup:Dynamic Gan\;0\;;
1 ExplicitGroup:opencv\;0\;;
1 ExplicitGroup:conferences\;0\;;
2 ExplicitGroup:cvpr18\;0\;;
}
